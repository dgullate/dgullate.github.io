@misc{gallegoOpponentAwareReinforcement2019,
 abstract = {We introduce Threatened Markov Decision Processes (TMDPs) as an extension of the classical Markov Decision Process framework for Reinforcement Learning (RL). TMDPs allow suporting a decision maker against potential opponents in a RL context. We also propose a level-k thinking scheme resulting in a novel learning approach to deal with TMDPs. After introducing our framework and deriving theoretical results, relevant empirical evidence is given via extensive experiments, showing the benefits of accounting for adversaries in RL while the agent learns},
 author = {Gallego, Victor and Naveiro, Roi and Rios Insua, David and GÃ³mez-Ullate, David},
 copyright = {arXiv.org perpetual, non-exclusive license},
 doi = {10.48550/ARXIV.1908.08773},
 keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
 note = {\subsectionOther

Substantially extends the previous work: https://www.aaai.org/ojs/index.php/AAAI/article/view/5106. This article draws heavily from arXiv arXiv:1809.01560},
 publisher = {arXiv},
 title = {Opponent Aware Reinforcement Learning},
 urldate = {2025-10-19},
 year = {2019}
}
